"""
Demo script showing Hydra multirun functionality with GPU acceleration.
"""

import subprocess
import os
from pathlib import Path


def run_demo():
    """Run a demo of multirun functionality."""
    print("ğŸš€ Hydra Multirun Demo - GPU Accelerated Training")
    print("=" * 60)

    # Check GPU availability
    print("\nğŸ“Š GPU Status:")
    result = subprocess.run(
        [
            "python",
            "-c",
            "import torch; print(f'CUDA Available: {torch.cuda.is_available()}'); "
            "print(f'GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"None\"}')",
        ],
        capture_output=True,
        text=True,
    )
    print(result.stdout)

    print("ğŸ¯ Running Multi-Model Comparison...")
    print("Command: python train_hydra.py -m model=collaborative,content_based train.epochs=2 train.batch_size=256")
    print("\nThis will:")
    print("  â€¢ Train 2 different models (Collaborative Filtering & Content-Based)")
    print("  â€¢ Use GPU acceleration automatically")
    print("  â€¢ Save outputs in organized directory structure")
    print("  â€¢ Generate comparison logs and metrics")

    print(f"\nğŸ“ Outputs will be saved in:")
    print(f"  outputs/movie_recommendation/multirun/YYYY-MM-DD_HH-MM-SS/")
    print(f"  â”œâ”€â”€ 0_collaborative/    # Collaborative filtering results")
    print(f"  â”œâ”€â”€ 1_content_based/    # Content-based filtering results")
    print(f"  â””â”€â”€ multirun.yaml       # Multirun configuration")

    # Check if outputs directory exists
    outputs_dir = Path("outputs/movie_recommendation/multirun")
    if outputs_dir.exists():
        print(f"\nğŸ“Š Existing multirun sessions:")
        for session_dir in sorted(outputs_dir.iterdir()):
            if session_dir.is_dir():
                print(f"  â€¢ {session_dir.name}/")
                # List job directories
                for job_dir in sorted(session_dir.iterdir()):
                    if job_dir.is_dir() and not job_dir.name.startswith("."):
                        print(f"    â””â”€â”€ {job_dir.name}/")

    print(f"\nğŸ’¡ Additional multirun examples:")
    print(f"  # Hyperparameter sweep:")
    print(f"  python train_hydra.py -m train.learning_rate=0.001,0.01,0.1 train.batch_size=256,512")
    print(f"  ")
    print(f"  # All model comparison:")
    print(f"  python train_hydra.py -m model=collaborative,content_based,hybrid,deep_cf")
    print(f"  ")
    print(f"  # Advanced sweep:")
    print(f"  python train_hydra.py -m model=collaborative,deep_cf train.epochs=10,20 train.learning_rate=0.001,0.01")

    print(f"\nâœ¨ Benefits of Hydra multirun in outputs directory:")
    print(f"  â€¢ ğŸ—‚ï¸  Organized output structure")
    print(f"  â€¢ ğŸ”„  Parallel job execution")
    print(f"  â€¢ ğŸ“Š  Easy experiment comparison")
    print(f"  â€¢ ğŸ·ï¸  Automatic job naming and numbering")
    print(f"  â€¢ ğŸ’¾  Complete configuration tracking")
    print(f"  â€¢ ğŸš€  GPU acceleration for all jobs")


if __name__ == "__main__":
    run_demo()

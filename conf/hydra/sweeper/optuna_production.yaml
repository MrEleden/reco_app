# Production Optuna Sweeper Configuration
# Comprehensive hyperparameter optimization for production deployment

# @package hydra.sweeper
_target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper

# Production study settings
study_name: "production_multi_model_optimization"
storage: null  # Use in-memory storage for simplicity
n_trials: 100  # Comprehensive search for production
n_jobs: 4  # Parallel jobs for faster optimization
direction: minimize  # Minimize validation RMSE

# Required parameters for Hydra Optuna plugin
search_space: null
custom_search_space: null

# Production hyperparameter search space (using params format)
params:
  # Model selection (your original intent)
  model: collaborative,content_based,hybrid,deep_cf
  
  # Learning rate optimization (discrete choices for log-like spread)
  train.learning_rate: 0.0001,0.0005,0.001,0.005,0.01,0.02,0.05
  
  # Batch size optimization (powers of 2 for memory efficiency)
  train.batch_size: 128,256,512,1024
  
  # Regularization parameter that exists in all models
  model.dropout: 0.1,0.2,0.3,0.4,0.5
  
  # Training dynamics (discrete choices for log-like spread)
  train.weight_decay: 0.0001,0.0005,0.001,0.005,0.01
  
  # Early stopping patience
  train.patience: 5,8,10,12,15

# Sampler configuration
sampler:
  _target_: optuna.samplers.TPESampler
  seed: 42
  n_startup_trials: 10
  n_ei_candidates: 24